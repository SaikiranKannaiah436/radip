from scipy.spatial import distance
import numpy as np
from numpy.core.umath_tests import inner1d
import comparative_works

class ReportWriter:
    def __init__(self,
                 training_batch_handler,
                 validation_batch_handler,
                 test_batch_handler,
                 parameters,
                 report_df):
        """
        training_batch_handler:
        validation_batch_handler:
        test_batch_handler:
            The three data groups to do full hyperparam tuning on a network.
            Other models may need it.
        parameters: The list of all params.
        report_df: the final report generated by the test run. It should only contain d=0 snippets.
        
        """
        compares = comparative_works.comparative_works()
        HMM_errors = compares.HMMGMM(training_batch_handler,validation_batch_handler,test_batch_handler,parameters,report_df)
        RNN_model_errors = self._score_model_on_metric(report_df)
        # for every other model:
        #   report_df = run_model
        #   model_errors = self._score...()
        # collect all scores and write a CSV or HTML or something.
        ideas = None

    # Here, there are many options
    # A) metric variance. LCSS, Hausdorff, etc
    # B) Statistical variance:
        # best mean
        # best worst 5% / 1% / 0.1% <-- It took me ages to get data for a reasonable 0.1% fit!
    def _score_model_on_metric(self, report_df, metric=None):
        scores_list = []

        horizon_list = [5, 10, 13]#, 25, 38, 50, 63, 75]
        # horizon_dict = {}
        # for dist in horizon_list:
        #     horizon_dict[dist] = []

        for track in report_df.iterrows():
            track_scores = {}
            track = track[1]

            preds = track.outputs[np.logical_not(track.trackwise_padding)]
            gts = track.decoder_sample[np.logical_not(track.trackwise_padding)]

            ### EUCLIDEAN ERROR -- Average
            euclid_error = []
            for pred, gt in zip(preds[:,0:2], gts[:,0:2]):
                # Iterates over each time-step
                euclid_error.append(distance.euclidean(pred, gt))
            ### /EUCLIDEAN

            ### HORIZON METRICS
            for dist in horizon_list:
                if dist >= len(preds):
                    continue
                euclid_error = distance.euclidean(preds[dist, 0:2], gts[dist,0:2])
                #horizon_dict[dist].append(euclid_error)
                track_scores["horizon_steps_" + str(dist)] = euclid_error

            # Now horizon_dict is keyed by timestep, and contains lists of distance errors
            # Mean, Median, 5% etc can now be done on those arrays.


            ### MODIFIED HAUSDORFF DISTANCE
            # Pulled shamelessly from https://github.com/sapphire008/Python/blob/master/generic/HausdorffDistance.py
            # Thanks sapphire008!
            #TODO Untested. I think it needs to be trackwise, as above
            (A, B) = (preds[:, 0:2], gts[:, 0:2])
            # Find pairwise distance
            D_mat = np.sqrt(inner1d(A, A)[np.newaxis].T +
                            inner1d(B, B) - 2 * (np.dot(A, B.T)))
            # Calculating the forward HD: mean(min(each col))
            FHD = np.mean(np.min(D_mat, axis=1))
            # Calculating the reverse HD: mean(min(each row))
            RHD = np.mean(np.min(D_mat, axis=0))
            # Calculating mhd
            MHD = np.max(np.array([FHD, RHD]))
            ### /MHD


            track_scores['euclidean'] = np.mean(np.array(euclid_error))
            track_scores['MHD'] = MHD


            scores_list.append(track_scores)
        return scores_list

#TODO Make a report_df.pkl for the results, and add a if name is main here to load said cached results.